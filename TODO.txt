【TODO】
打包和更新工具
ConfigEditor 自动完成: Foreign；自动id，Load 的时候记录maxid，以后编辑AddRow都使用这个递增；
ConfigEditor 更多自动完成？普通的列默认最近使用的n个值，根据输入在列中查找最匹配的。
ConfigEditor enum 现在不支持引用在其他文档定义的，有需要了再来加。
war？一个module集合。定义export？private？App.Instance？生成代码使用基类，不再使用具体类型，感觉没必要：应用使用独立进程更加安全灵活些。
----------------------------------------------------------------------------------------------------------------------------------
DatabaseTikv.OperatesTikv
ServiceConf.Acceptor ip="@internal" "@external"
Task
Universe
Zege
AchillesHeelDaemon：安全级别从jvm级别提升到操作系统。保留线程守护，增加进程守护。两个守护兼容：
  gs启动的时候检查mmap，发现自己是daemon启动的，就开启进程守护（向mmap报告和读取命令），否则还是原来的线程守护。
Bean 依赖环检测。允许容器依赖环。

【2022/7/15】

------------------------------------------------------------------------------------------------------------------------------
tag 1.0.0 Stable? ^_^
------------------------------------------------------------------------------------------------------------------------------
TableX.FlushWhenReduce 去掉回调方式，去掉Period支持（直接抛异常）。
raft.agent 永远尝试会造成大量服务不可用风险。
java Remove ServiceInfo.LocalState
1. BUG，ReduceInvalidAllLocalOnly 没有Flush。
2. BUG，TableX.Load 发现 Invalid 再去Acquire并Storage.Load时，如果本地记录是脏的，数据就会被覆盖。
   刚才TableX.Load的问题造成的可能原因分析：本地数据被Daemon.Release，是没有刷新到后台的，
   如果中间重新连上Global就会出现这个情况。但奇怪的是Daemon在你跑测试的时候是没有在工作的。
   这点的其他可能原因你也分析一下？
   虽然补丁好像可以Load时，if (!Record.Dirty) Storage.Load；但这个没有找到真正原因前，这个补丁有点危险。
   【修改：Reduce的时候，锁内执行Flush】

RedirectHash & RedirectAll & ChoiceHash - 单点数据分块支持与一致性Hash算法修改（原方案有问题：数据分块不能在服务器选择之后保持独立性）
	DataConcurrentLevel：数据分块数量。
	1. DataConcurrentLevel大于1 服务器选择：
	var ha = hash(account);
	var di = ha % DataConcurrentLevel; // account被分成Level个集合，每个集合访问一块数据
	var h = hash(di); // 不再考虑原始hash，参见后面第2.点。
	var server = ConsientHash(h);
	问题：
	   DataConcurrentLevel个数据块的访问是不是被分割成独立集合，每个集合在一个server内访问？
	2. DataConcurrentLevel=1服务器选择。
	var ha = hash(account);
	var server = ConsientHash(ha);
	问题：
	   相同的account在一个server上。这个显然没问题了。
ServiceManager.Agent Remove ServiceInfo.LocalState
【重大BUG】 即使锁内。Record.Global.State 可能没有提升到需要水平。需要重新_check_。
一致性hash负载分配算法, 【c# 没有TreeMap.tailMap。】
Table.WalkKey
Global-Server错误码分析
1. Warning
global 统计增加了Acquire和Reduce ResultCode的统计, GlobalRaft跑Simulate时,Acquire出现过以下失败情况:
 public static final long Exception = -1;
 public static final long RaftRetry = -15;
 int AcquireShareDeadLockFound = 21;
 int AcquireShareAlreadyIsModify = 22;
 int AcquireModifyDeadLockFound = 23;
 int AcquireModifyAlreadyIsModify = 25;
 int AcquireShareFailed = 26;
 int AcquireModifyFailed = 27;
2. Fatal
ERROR [] Table: RocksRaft Process Exception
java.lang.IllegalStateException: CacheState state error
 at Zeze.Services.GlobalCacheManagerWithRaft.AcquireShare(GlobalCacheManagerWithRaft.java:188)

【2022/6/11】

------------------------------------------------------------------------------------------------------------------------------
tag 0.9.9 Random Sleep For Global-Dead-Lock and Too-Many-Try & Global Restart ...
------------------------------------------------------------------------------------------------------------------------------
【TryWaitFlushWhenRecude 去掉啦】
Too Many Try: Fresh机制下由Global提供排队方案草稿：
  1. Server发现本地Fresh，拒绝Reduce。
  2. Global发现由于Fresh的拒绝，把申请者加入队列。
  3. Server把set Fresh=false时，发送通知给Global。
  4. Global收到Fresh==false通知，选择队列中的一个申请者开始处理。
  5. Global-Fresh队列管理。
     需要定时轮询的方式启动队列中的请求进行重做，防止Fresh=false通知丢失。
     请求总超时管理按一般请求超时处理。
     问题：请求第一次来的时候要不要判断Fresh队列不为空，然后马上加入队列。
  【死锁检测忙等问题】
     由于死锁检测必须返回结果，没法使用队列，所以这个问题不好解决。
     死锁检测原来的忙等解决方案是：TryWaitFlushWhenRecude，但仍然存在一个忙等窗口：
     当一个申请在进行过程中，CacheState还没有更新时，忙等仍然存在。
  【总结】
     用随机延迟一起解决Fresh排队和死锁检测忙等，上面的Fresh队列也不实现了。
-------------------------------------------------------------------------------------------
Arch：模块默认订阅类型设置为，SubsribeTypeSimple。（准备以后改成一致性hash算法）。
Global宕机：Server重连发送ReLogin，此时新启动的Global需要拒绝ReLogin，然后Server释放本地所有锁，重新发Login才能登录。
Gen: transient 应用到所有版本。
Too Many Try: Fresh机制下由Global提供排队方案草稿：
  0.【先采用临时方案】Server在RedoAndReleaseLock时随机Sleep延迟。

------------------------------------------------------------------------------------------------------------------------------
tag 0.9.8 AchillesHeel & Handshake & Too Many Try
------------------------------------------------------------------------------------------------------------------------------
Handshake 是否加密可以配置。默认不加密。
AsyncSocket.VerifySecurity 在 CHandshakeDone处理时调用一次。不再需要在DispatchProtocol时调用。
Global错误处理：GS增加AchillesHeelDaemon，申请token（特别的keepalive）机制，本地释放锁超时，如果稍有不正常，就自杀。
too many try: 从Global得到锁以后，确保本地至少用过一次（事务成功），才允许Reduce。
Global-Server 错误恢复测试。1. Server 强制杀掉，8秒内重启。2. Server 强制杀掉，Global一定时间后回收记录锁。
Java Apply Zeze.Transaction.Logs

------------------------------------------------------------------------------------------------------------------------------
tag 0.9.7 Java TableCache SoftReference Fix Bug Timestamp Value Access Order
------------------------------------------------------------------------------------------------------------------------------
Global错误处理：GS增加AchillesHeelDaemon，申请token（特别的keepalive）机制，本地释放锁超时，如果稍有不正常，就自杀。【草稿】
LinkedMap.BLinkedMapNodeValue 里面保存了key，但是walk接口没有返回，需要在dynamic里面再次定义。【callback返回key(id)，而不是nodeid】
LinkedMap.GetOrAdd
Zege 框架搭建完成。
java ServiceManager.AgentClient.DispatchProtocol Run In IO-Thread。
java Zeze.Applicate.deleteDirectroy: while(exist) { delete() }

------------------------------------------------------------------------------------------------------------------------------
tag 0.9.6 zege start & c# raft ready
------------------------------------------------------------------------------------------------------------------------------
简介
	一个简单IM系统，支持大量好友，大量群成员。
目的
	用来验证zeze消息发送转发能力。
语言
	Server=java，Robot=java，Client=???
详细
	. 基于账号（不是Roleid）
	. 相同账户允许重复登录。
	. 给群发送消息使用RedirectHash。
	  比如有1000台server，那么群成员大概率平均分布，那么每个成员发送消息广播时，对群列表的利用率极低。
	  使用hash(group.Id)把群的广播请求固定分配到某台server上，提高群成员列表的利用率。
	  缺点是需要转发一次消息，但相当合理。
	. 大量群成员一起说话是没法聊的。所以实际上当群成员超过一定量（比如1000）时，需要分目录。
	  最终群成员被组织到一个部门树中。每个部门（包括根）都有自己的成员列表，限定数量内允许聊天。聊天不包含子部门。
产出
	Zeze.Collections.Tree
可能
	元宇宙实现一个基于RoleId的客户端内的好友系统，意义不大，应该独立成一个系统。
	可以考虑把这个测试程序发展成元宇宙的好友系统。以后提供unity内的client,以及android,ios,等等等...
	另外元宇宙server端需要访问好友系统，则通过server-server接口。
代号
	"Zege"，泽哥的意思

c# raft BUG: Zeze.Raft.LogSequence:849行TryAdd失败【张路找到，异常导致LeaderAppendLogs没有Rollback，然后在关闭Raft的时候，并发的还在处理中请求进入锁导致失败】

------------------------------------------------------------------------------------------------------------------------------
tag 0.9.5 c# ready(except raft)
------------------------------------------------------------------------------------------------------------------------------
1. raft 异步测试【未解决TryAdd失败BUG】
2. Global With Raft 异步测试【未进行】
3. 查找所有Wait并确认【Done】
4. Net Full Async【Done 但没有达到Global可以直接在DispatchProtocol里面await的目的】
5. Rewrite Scheduler【简单处理一下，使用的地方比较多，先这样啦】
6. UnitTest TestBag没过(呼叫肖丽杨)。

ServiceManager.ServiceInfo.Identity 编码：'@'开头为string，否则为int。Identity排序如果int按int的大小排序。
java ASYNC GlobalWithRaft Question：1. Transaction.Current is ThreadLocal？2. try ... finally? 3. exception? 【决定使用虚拟线程】

------------------------------------------------------------------------------------------------------------------------------
tag 0.9.4 Online.ReliableNotify & Global.LruTryRemoveCallback
------------------------------------------------------------------------------------------------------------------------------
ReliableNotify - Sample(Zezex).client: 客户端可以延迟确认，如果发现Index不匹配，可以发送确认Rpc并且带上Sync标记进行重新同步。
Global.RocksRaft.LruTryRemoveCallback

------------------------------------------------------------------------------------------------------------------------------
tag 0.9.3 inherit bean (conf+cs only)
------------------------------------------------------------------------------------------------------------------------------
1. bean继承实现
   【注意】class B : A; List<A>中被放入B时，Decode成A或者失败或者Encode报错。
   【注意】继承要实现动态，必须配合dynamic使用。如，List<dynamic:A>这样里面可以放A及A的子类，可以被正确encode/decode。

------------------------------------------------------------------------------------------------------------------------------
tag 0.9.2 Gen: new type format; collection can hold dynamic type now
------------------------------------------------------------------------------------------------------------------------------
1. 新的模板参数声明格式
   <variable id="1" name="ListInt" type="list[int]"/>
   <variable id="2" name="SetInt" type="set[int]"/>
   <variable id="3" name="MingIntInt" type="map[int,int]"/>
   # 兼容旧的key，value声明方式，同时指定将抛异常。
2. dynamic 统一包含Bean的定义方式
   <variable id="1" name="Dynamic" type="dynamic" value="bean1,bean2">
      <value bean="bean3"/>
   </variable>
   改成
   <variable id="1" name="Dynamic" type="dynamic">
      <value bean="bean1"/>
      <value bean="bean2"/>
      <value bean="bean3"/>
   </variable>
   直接在variable的属性value中声明方式不再支持，统一在包含的element中声明。
3. dynamic 指定基类&可以放入容器中
   【基类即Bean将实现继承，仅在dynamic中才支持声明基类，下面是例子】
   【继承实现将有 @张路 完成，目前仅完成声明基类的解析】
   【解析基类是所有版本的，计划具体实现仅用于platform="conf+cs"，由张路决定】
   <variable id="1" name="ListInt" type="list[dynamic:BBase]"/>
   <variable id="2" name="SetInt" type="set[int]"/> set不支持包含dynamic，特别放这里说明一下
   <variable id="3" name="MingIntInt" type="map[int,dynamic:BBase]"/>
   <variable id="4" name="BeanWithBase" type="dynamic:BBase"/>

------------------------------------------------------------------------------------------------------------------------------
tag 0.9.1 Java TableCache SoftReference 2022.5.13
------------------------------------------------------------------------------------------------------------------------------
TableCache增加一级RocksDb的缓存，不容易受限于内存。Java SoftReference<T>.
TableCache.Clean 整体考虑。
<<<
TableCache 原来想增加一级基于RocksDb的巨大缓存，由于这个缓存有不少状态需要快速访问，完全增加一级效率不够高，所以决定做个简化版本。
1. TableCache.Lru 还是拥有所有配置的容量内的记录，总是持有必要的状态数据。
2. 记录的用户数据使用 SoftReference 引用。
3. 记录本身还是按旧的机制管理生命期和状态。需要的时候会同步RocksDb。
4. SoftReference 回收的时候，保存一份到RocksDb中。【原子问题需要考虑】
5. SoftReference 不存在，从RocksDb装载。【原子问题需要考虑】
6. RocksDb虽然是持久化到硬盘的，但是重启会全部删除。
9. 使用RocksDb保存被GC的用户数据这个特性做成可选（又是需要if判断）?【没有实现】
*. Cache 实现草稿
【一】
private KV<Record1<K,V>, V> TableX.Load(K key) {
    ...
    if (r.getState() is right) {
        var strong = r.Soft.get();
        if (null == strong && false == r.getDirty()) { // dirty 时意味着应用做出了修改但还没保存，此时不需要load
            strong = RocksDb.get();
            r.Soft.set(strong);
        }

        // strong需要返回，不能从r.soft里面再次获取
        // 使用Load的地方：
        // 1. Transaction.get等。需要把strong记到事务的RecordAccessed中，在事务结束前都不能触发soft回收。
        // 2. selectDirty。可以事务外使用，使用者自己管理strong生命期。
        return KV.Create(r, strong);
    }
    ...
    // load from storage
    var strong = TStorage.Find(key, this);
    RocksDb.put(); // 【原则】保持Rocks和后台数据库一致。
    r.Soft.set(strong);
    ...
    return KV.Create(r, strong);
}

【二】
Record.setDirty(bool value) {
    Dirty = value; 【原来的】
    StrongRef = value ? soft.get() : null; // 脏数据在记录内保持一份强引用。
    // 由于记录不存在时，StrongRef可为null，所以原来的bool Dirty不能使用 StrongRef != null 代替。
    // 需要分成明确的两个变量。
}

【三】
RecordAccessed 增加 Bean StrongRef，保存Load的返回值里的bean引用。

【四】
public void Record1.Flush(Database.Transaction t) {
    ...
    if (null != snapshotValue)
        RocksDb.put();
    else
        RocksDb.Remove();
}

【五】
public void Record1.SetDirty() {
    ...
    case Immediately:
        RocksDb.put(); // Immediately 模式需要在这里保持Rocks和后台数据库一致。它走不一样的Flush流程。
        break;
}

【六】
private boolean TableCache.Remove(Map.Entry<K, Record1<K, V>> p) {
    ...
    RocksDb.remove();
    // 从cache中删除，也需要删除持久化的，这个违背了【原则：RocksDb和后台数据库一致】，
    // 但是不删除，会导致长期运行，本地cache一直积累。
    return true;
}

【七】
public void Record1.Encode0() {
    ...
    snapshotValue = StrongDirtyValue != null ? getTTable().EncodeValue((V)StrongDirtyValue) : null;
    // StrongDirtyValue 最新的value。
}

【原则】
1. RocksDb和后台数据库一致。
2. 事务内访问的记录不能被回收。
3. selectDirty返回的strongref需要使用者自己管理。

>>>

【2022/5/11】

Global 性能测试
------------------------------------------------------------------------------------------------------------------------------
tag 0.9.0 java ready
------------------------------------------------------------------------------------------------------------------------------
TableKey,GlobalTableKey TableName -> TableId
Java New Changes: 1. Gen 2. Collections 3. Log 4. Changes & remove CreateChangeVariableCollector 5. Transaction & Savepoint
Java Global Performance: 【张路】26w/s 200M带宽
3. Test TestGlobal Simulate 异步测试【已经通过测试了 2022.5.9】
把 RocksRaft Changes 应用到 Zeze 中，让 Zeze 实现Bean任意级别的更新。
仅支持整个Bean的订阅。
log factory 问题。（不同步到其他进程没有这个问题）
动态订阅。add listener和notify原子问题。【收集和通知一致，不会出现收集丢失。】
Game.Bag Listener
Online Account （c#）
Global java 异步化： TaskQueueAsync 任务需要参与到队列的推进。全异步和RocksRaft.Transaction.ThreadLocal问题，需要自己实现一个类似AsyncLocal的机制。
StableLinkSid Done(Need Test)
StableLinkSid Prepare：分离LinkName,LinkSid到独立表中。
Arch remove ProviderSessionId；Rename ProviderId to ServerId
Online Test 【肖丽杨】Java
RocksRaft Collection.List LogList
【张路已完成】OpLogs=List<OperateLog>。list中的Bean更新规则：Encode的时indexOf所有的Changed找到索引，Apply=list.get(index).Apply(beanLog)。
2. c# 1) LoadReporter. 
3. java 1) LoadReporter. 
1. Online Memory Table 可以存储在线相关数据。
   功能
   a) Local.Online.Count
   b) Foreach Local Online
   c) LocalData Set Get
   维护 memory Table 准确的机制
   a) 本机正常Login/Logout/LinkBroken
   b) 本机Logout/LinkBroken丢失或迟到，而已经在其他机器上Login，此时需要Redirect过来。
   c) Redirect丢失，本机需要一个机制遍历TableCache，慢慢检测并清除Memory中登录状态无效的数据。
   事件
   Logout事件需要带上当前Memory表中存的用户数据。
1. c# Arch RedirectAll & Test
2. c# Game.Rank TODO GetRankAll Test
1. Zezex Onlines TransmitInProcedure 需要重写。需要改成使用ProviderDirectService.ProviderByServerId。
1. FewModifyList
2. FewModifyMap
c# RedirectGenMain 内建模块Redirect生成。
Java RedirectGenMain 内建模块Redirect生成。
Java 2) Online Logout Check Not Owner.
Java 3) ProviderImplementWithOnline
Java 4) ProviderDirectWithTransmit
c# 2) Online Logout Check Not Owner.
c# 3) ProviderImplementWithOnline
c# 4) ProviderDirectWithTransmit
Global 死锁. lock(CacheState) lock(CacheHolder)之间互相依赖。
	3月份调整代码，试图对同一个session(每个serverId对应一个，即CacheHolder)进行互斥同步时的改动引进的bug。
	去掉了 lock(session)，恢复成原来的 tryBind，tryUnbind里面lock，不持有。仔细想了一下。
	互斥由tryBind,tryUnbind的逻辑保证，只允许一个serverid的实例的session前进到下一步，其他都失败。
Builtin Module UnRegister 实现。
c# Zeze.Game.Bag
c# Zeze.Game.Rank
c# Zeze.Game.Online
Java Zeze.Game.Rank Test【张路】
Java Zeze.Game.Bag Test【王鹏安排】
Java Zeze.Game.Online 【张路】
Java Zeze.Game.Bag
Java Zeze.Game.Rank
Redirect 支持异步实现。【Java张路】 c# RedirectAll 错误处理。
c# Arch : redirect Hash & Server Test Ok
c# Arch Redirect Hash & Server async ready.
c# Collections Queue LinkedMap
c# Component DelayRemove AutoKey RedoQueue RedoQueueServer
Java Arch Test：RedirectToServer,RedirectHash Done
ServiceManager.Agent lock 模式：改成全局锁Agent。单线程化。回调也在锁内执行。【放弃，锁内回调风险太高】
ServiceManager: Provider之间连接成功的时候，Pending还没到达。
ServiceManager.ReadyCommit模式时，订阅启动全新广播。

【2022/4/11】

Load 移到 Zeze.Arch 里面，里面使用的MyConfig相关配置移到LoadConfig中。【使用OnSetServerLoad，Game.Load复用暂不考虑了】
Java Arch Callback在不同Redirect模式下的限定和检查
CommitServiceList,ReadyServiceList 不发送整个列表，仅发送系列号。
问题：Java Arch ServiceManager ReadyCommit 依赖Provider之间的连接，但是连接又依赖Indentity-List-Ready。【暴露Pending状态的列表】
ProviderSession 增加 Set(ServiceName,Identity) OnSocketClose 时 foreach (var (s,i)) SetServiceIdentityReadyState(s, i, null);
SetServiceIdentityReadyState(+ServiceName, identity, state);【误会，这个定义在SubscribeState里面的，不需要ServiceName了】
Linkd-Provider之间的连接建立比Provider-List通告早，需要查询得到。【没问题，异步问题已经处理。当连接任何时候准备好，调用SetServiceIdentityReadyState设置进去】
java Arch: ModuleRedirect 重构。
	【左尧完成Java了？】Zezex.ModuleRedirect 增加 TransactionLevel 注解配置。
	Zezex.ModuleRedirect 去掉依赖Session生成hash模式；RunMyMethod去掉mode；
java Arch: 重构 Provider：分为 Provider(linkd-gs),Provider2(gs-gs)。预计负载算法还需要公用。
Load ServiceManager 新增按按Ip-Port组织的订阅和通告。
Load 更新。
RedoQueue Client 【未测试】
RedoQueue
{
	1）存储：QueueId。 RocksDb<TaskId, Full_Encoded_Net_Rpc> 持久化的。
	2）Task.Id long 递增 Rpc
	Zeze.ServerApp
	1) zeze.table<QueueId, LastTaskId> 记住已经同步的最后的任务id，
	2) 功能：每个QueueId，for (LastTaskId, end) { Run(task); zeze.table.LastTaskId = task.Id; }
	* 特性：允许 Zeze.ServerApp 回档，回档以后，从旧的LastTaskId开始重做任务。
}
Zeze.Component dynamic bean动态增加类型的能力。
LockAsync 单元测试。关键：TryEnterXXXLock。
Queue
GCTable(每个ServerId一个Queue), rename to DelayRemove
Component.AutoKey
java LinkedMap dynamic 动态注册问题。
换换脑子，写一个java版基于KV的LinkedMap
async Connector GetReadySocket WaitReady 
GlobakWithRaft java test【张路】【基本可用了】
GlobalAgent NormalClose 超时设置。必须加大或者无限等待。
zeze async await test。remove SimpleThreadPool!
database 异步测试
ServiceManager 异步化
TestCheckpoint 整个跑会失败，单独一个一个测试跑成功。【加了async，没有await】
async TestCheckpointModeTable 直接运行 Trans 目录会出错，单个或者选择开始的几个运行没问题。【AsybcLocal<Transaction>重用有问题，去掉重用】
rocksraft 异步测试【raft还有bug，但这个能测试通过】
Raft.AppendLog 加一个try catach，所有的内部错误都转换成RaftRetryException，这样就不会把内部异常漏给应用了。
AsyncRocksDb
AsyncExecutor
database 异步化 
Global With Raft 异步化
rocksraft 异步化
raft 异步化
Global 异步化
c# zeze 嵌套存储过程RunWhileRollback在外层事务Commit时需要处理的问题。还有按调用顺序回调的问题。
	Savepoint 成员变量 CommitActions RollbackActions
	Savepoint.Commit(nest) CommitActions.AddAll(nest.CommitActions);
	Savepoint.Rollback(nest) CommitActions.AddAll(nest.RollbackActions); RollbackActions.AddAll(nest.RollbackActions);
	Transaction.FinalCommit() foreach (var a in LastSavepoint.CommitActions) a.trigger();
	Transaction.FinalRollback() foreach (var a in LastSavepoint.SavedRollbackActions) a.trigger();
zeze async await compile ok!
Raft.Shutdown 先关闭网络，有错误也不返回了。
TaskOneByOne 重构，新增支持调用异步存储过程和异步协议处理。
Global PulseAll 必须，需要全部等待在死锁检测的线程全部再来一遍，否则仍有可能死锁。
GlobakWithRaft java compile ok!
RaftLog.DecodeTermIndex 仅Decode两个内部变量，不包含应用日志。避免初始化循环依赖。
GlobalWithRaft c# test 1111
	CacheHolder 访问 Instance 是旧的代码，引用到旧的static上面了。
	AcquireModify Reduce Share 的时候，比如返回原来的事务才能修改数据。
	* 这点非Raft版本Global(c#&java)都改成返回主流程修改状态数据。
GloblWithRaftAgent c# WaitLoginSuccess
RocksRaft java
RocksRaft rrjava
GlobalRaft Agent.Initialize & Test
GlobalRaft Agent GetReadySocket() Login ReLogin	
GlobalRaft GlobalSerialId 问题解决初步想法：由RocksRaft提供AtomicLong实现，每个事务结束，
成功同步到其他节点。这个Global拿来区分记录申请次数，需要一直递增，可以跳着分配（浪费）。
细节：lock (Raft) { if (atomiclong.get() > lastAppendLog) doAppendLog; }

【2022/3/11】

Global 流程确认：独占排他性，Raft版本部分操作仅Leader有效?
Global NormalClose 需要锁定Session，释放所有锁，确保释放完之前新的服务器不会登录进来。【raft及非raft版本都需要考虑】
Global Cleanup 需要锁定，释放所有锁，这里无法通过lock(session)保护。
Global Login Bind以后，释放存在的锁，看来没有问题，需要确认。
Global ReLogin 不涉及所释放，能Bind成功就表示ReLogin成功，看来没有问题，需要确认。

GlobalCacheManagerWithRaft 关键Transient：CacheState.AcquireStatePending 仅在Leader上使用，不需要同步到Follower。
RocksRaft & rrcs GenTable OpenTable 提供模板化打开表格能力。
RocksRaft Gen Bean.Variable.Transient Attribute
RocksRaft Gen
	. Bean.Kind : "bean" "beankey" "rocks" "dynamic" ""
	. project platform add type: "internal+cs" "internal+java" 增加属性 IsInternal 仅把原来Gen/下的类生成到src空间下，src下的代码不生成。
RocksRaft Collection.Set
RocksRaft Raft.AppendLog
RocksRaft NestProcedureContainer Test
RocksRaft Simple NestProcedure Test
RocksRaft Edit Bean In Container
Raft.AppendLog Future Add Duplicate Index. Fatal!【观察不到了！】
c# Global 慢？【网络事件也和普通Task共享了一个线程池，造成rpc.result处理也排队的结果，等async解决】
RocksRaft 日志收集基本完工。
Raft.Test 只删除日志相关数据库。保留重复请求数据库。
Raft.UniqueRequestSet.Put 优化：先读取并检查状态，减少写操作。
Raft.UniqueRequest.Expired
Raft.Expired
Raft.AppendLog 带上当前Rpc.Result，当发现重复请求的时候返回
Raft.LogSequence.FindMaxMajorityLogIndex 新实现，不需要遍历Log。
Raft.LogSequence.FindMaxMajorityLog 里面的 ReadLog 优化掉。
1. Log.cs: logger.Fatal("truncate committed entries"); Fatal!【选举移动代码的BUG：Term在递增前使用】
Raft.Apply 分批进行，让其他操作有运行机会。解决启动时，apply整个日志锁住时间太长的问题。
Raft.State.Timeout 恢复状态模式。【不恢复，就轮询了】
RaftLog.ToString More Detail
Raft.Agent TryGetReadySocket 总是 null。【没有发现问题】
Net.Connector.OnSocketHandshakeDone Fail 原因。【没有发现问题】
Raft.Shutdown 的时候快速失败-Cancel在Future上等待的任务。【有时shutdown会很慢】
2. Raft.Vote Leader 第一个Hearbeat被拒绝;  导致不停的选举。
   SaveLog.RocksDb.Put 卡住导致超时？
3. Raft.Count 错误处理问题？请求已经被处理，但是结果丢失，重发请求发生了不会重做的异常，这会导致Count统计不正确。【Raft.AppendLog 检查LogSequence是否null】
Raft.Vote 优先级++++++++++++++++++++++++++ 初步考虑仅使用不同的延迟。RandomDelay + DelayPriority;
Raft.Agent 客户端卡住了? 【锁内 Env.Exit卡住了，导致OnTimer任务不停积累，最终线程数量巨大】
Raft.RocksDb.Open Try N Times
Raft.Vote 投票后推迟自己再次选举的时间，免得浪费。【现在代码注释掉了】
Raft.Log.FollowerOnAppendEntries 优化。
Raft.Log.Index 必须递增，去掉原来支持跳着分配的代码，并且在需要的地方增加错误检查。
Raft.Agent ActiveTime 重连功能删除，
Net.Connector 轮询重连，【恢复回状态检查实现，轮询改为10分钟的错误处理】
Net.Connector 轮询重连？以后恢复成连接断开才启动timer？先轮询，等raft稳定了再考虑。
Raft.Test 关闭2节点后，一直没有重启。【测试程序出错了】
